{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file is for assessing the models performances. It was used to get the results of the corss-validated models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from mask_functions import *\n",
    "from fastai.callbacks import *\n",
    "import gc\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "path = Path(f'/cs/home/khfy6uat/data/one_class_data_1024')\n",
    "\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "The original images, provided in this competition, have 1024x1024 resolution. To prevent additional overhead on image loading, the datasets composed of 256x256 scaled down images are prepared separately and used as an input. Check make-pneumothorax-oneCase-data for more details on image rescaling and mask generation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "\n",
    "SEED = 2019\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    #tf.set_random_seed(seed)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric used to assess the model performance\n",
    "def dice_overall(preds, targs):\n",
    "    n = preds.shape[0]\n",
    "    preds = preds.view(n,-1)\n",
    "    targs = targs.view(n,-1)\n",
    "    intersect = (preds * targs).sum(1).float()\n",
    "    total = (preds+targs).sum(1).float()\n",
    "    u0 = total==0\n",
    "    intersect[u0] = 1\n",
    "    total[u0] = 2\n",
    "    return (2 * intersect / total).mean()\n",
    "def dice_overall_adjusted(preds, targs):\n",
    "    n = preds.shape[0]\n",
    "    preds = preds.view(-1)\n",
    "    targs = targs.view(-1)\n",
    "    intersect = (preds * targs).sum(-1).float()\n",
    "    union = (preds+targs).sum(-1).float()\n",
    "#     u0 = union==0\n",
    "    return (2 * intersect / union)\n",
    "def iou_overall(preds, targs):\n",
    "    preds = preds.view(-1)\n",
    "    targs = targs.view(-1)\n",
    "    intersect = (preds * targs).sum(-1).float()\n",
    "    total = (preds+targs).sum(-1).float()\n",
    "#     u0 = union==0\n",
    "    return (intersect / (total-intersect))\n",
    "def CM_overall(learn,preds,ys):\n",
    "        mean_cm, _= generate_confusion(learn=learn,pred=preds,y_true=ys)\n",
    "        return mean_cm[1][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function generates predictions with using flip TTA (average the result for the original image and a flipped one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with flip TTA\n",
    "def pred_with_flip(learn:fastai.basic_train.Learner,\n",
    "                   ds_type:fastai.basic_data.DatasetType=DatasetType.Valid):\n",
    "    #get prediction\n",
    "    preds, ys = learn.get_preds(ds_type)\n",
    "    preds = preds[:,1,...]\n",
    "    #add fiip to dataset and get prediction\n",
    "    \n",
    "    learn.data.dl(ds_type).dl.dataset.tfms.append(flip_lr())\n",
    "\n",
    "    preds_lr, ys = learn.get_preds(ds_type)\n",
    "    del learn.data.dl(ds_type).dl.dataset.tfms[-1]\n",
    "    preds_lr = preds_lr[:,1,...]\n",
    "    preds = 0.5*(preds + torch.flip(preds_lr,[-1]))\n",
    "    del preds_lr\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return preds, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting div=True in open_mask\n",
    "class SegmentationLabelList(SegmentationLabelList):\n",
    "    def open(self, fn): return open_mask(fn, div=True)\n",
    "    \n",
    "class SegmentationItemList(SegmentationItemList):\n",
    "    _label_cls = SegmentationLabelList\n",
    "\n",
    "# Setting transformations on masks to False on test set\n",
    "def transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n",
    "    if not tfms: tfms=(None,None)\n",
    "    assert is_listy(tfms) and len(tfms) == 2\n",
    "    self.train.transform(tfms[0], **kwargs)\n",
    "    self.valid.transform(tfms[1], **kwargs)\n",
    "    kwargs['tfm_y'] = False # Test data has no labels\n",
    "    if self.test: self.test.transform(tfms[1], **kwargs)\n",
    "    return self\n",
    "fastai.data_block.ItemLists.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = Path(f'/cs/home/khfy6uat/data/data1024')\n",
    "\n",
    "def get_data(fold,tfms=get_transforms(),split=0.2,sz=sz,bs=bs):\n",
    "    # Create databunch\n",
    "    data = (SegmentationItemList.from_folder(path=path/'train')\n",
    "            .split_by_rand_pct(split,seed=10)\n",
    "            .label_from_func(lambda x : str(x).replace('train', '/masks'),classes=[0,1])\n",
    "            .transform(None, size=sz, tfm_y=True)\n",
    "            .databunch(path=Path('.'), bs=bs)\n",
    "            .normalize(stats))\n",
    "    return data\n",
    "\n",
    "# Display some images with masks\n",
    "# get_data(0).show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postive Cases DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = Path(f'/cs/home/khfy6uat/data/one_class_data_1024')\n",
    "\n",
    "data=get_data(0,sz=512,bs=12)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original DATA ALL CASES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(f'/cs/home/khfy6uat/data/data1024')\n",
    "\n",
    "data = (SegmentationItemList.from_folder(path=path/'train/train')\n",
    "        .split_by_idx(list(range(1000)))\n",
    "        .label_from_func(lambda x : str(x).replace('train/train', 'masks'), classes=[0, 1])\n",
    "        .add_test((path/'test').ls(), label=None)\n",
    "        .transform(get_transforms() ,size=256, tfm_y=True)\n",
    "        .databunch(path=Path('.'), bs=12,num_workers=0)\n",
    "        .normalize(imagenet_stats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading a saved Unet mdoel (not learner!)\n",
    "learn = unet_learner(data,models.resnet34,metrics=[dice,dice2,iou],callback_fns=[])\n",
    "\n",
    "learn.load('/cs/home/khfy6uat/bin/models/baseline_unet_fold_4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get prediction on data, this was mainly used to check if everything was fine so far \n",
    "preds,ys = learn.get_preds()\n",
    "preds = preds[:,1,...]\n",
    "ys = ys.squeeze()\n",
    "# dice_overall(preds,ys).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the classfier for the one case model results \n",
    "# a learner has to be first created to import a model into it \n",
    "path = '/cs/home/khfy6uat/data/classification_1024/classifier_data'\n",
    "import pretrainedmodels\n",
    "def resnext50_32x4d(pretrained=False):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n",
    "    return nn.Sequential(*list(model.children()))\n",
    "\n",
    "tfms = get_transforms(do_flip=True, flip_vert=False, max_lighting=0.1, max_zoom=1.05,\n",
    "                  max_warp=0.,\n",
    "                  xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n",
    "                             symmetric_warp(magnitude=(-0.2, 0.2))])\n",
    "data_cnn = (ImageList.from_folder(path)\n",
    "    .split_by_rand_pct(seed=10)\n",
    "    .label_from_folder()\n",
    "    .transform(tfms, size=1024)\n",
    "    .databunch(bs=2).normalize(imagenet_stats))\n",
    "print('learner created!')\n",
    "per = Precision()\n",
    "rec= Recall()\n",
    "learn_cnn = cnn_learner(data_cnn, resnext50_32x4d, pretrained=True, cut=-2,split_on=lambda m: (m[0][3], m[1]))\n",
    "#loading calssifier\n",
    "learn_cnn.model_dir='/cs/home/khfy6uat/bin/'\n",
    "learn_cnn.load('f1loss_CNN')\n",
    "learn_cnn.data=data\n",
    "#getting indices of images that the classifier predicts as negative samples \n",
    "p,ys_cnn=learn_cnn.get_preds()# getting predications \n",
    "#get predication of CNN and get class with higher confidence\n",
    "pred_cnn=F.softmax(p,1).argmax(dim=1)\n",
    "#find indicices that have negative class (here negative is labeled as (1))\n",
    "idx_empty=pred_cnn==1\n",
    "#creeate an empty mask templete \n",
    "empty_temp=torch.zeros(256,256)\n",
    "#replace all the negative cases to empty masks to reduce the flase psoitve rate \n",
    "# preds[idx_empty]=empty_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function gets predictions and applies three different post-processing techniques \n",
    "def get_multi_preds(learn,correct=False,idx=None):\n",
    "    empty_temp=torch.zeros(256,256)\n",
    "\n",
    "    print('Getting Raw preds')\n",
    "    preds,ys = learn.get_preds()#need a threshold \n",
    "    print('Getting TTA preds')\n",
    "    preds_tta,_=pred_with_flip(learn)#need a threshold\n",
    "    print('ARgmaxing ...')\n",
    "    preds_argmax=preds.argmax(dim=1)\n",
    "    preds = preds[:,1,...]\n",
    "    ys = ys.squeeze()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # if its a one case model the use the CNN to filter out the results\n",
    "    if correct is True and idx is not None:\n",
    "        preds[idx]=empty_temp\n",
    "        preds_tta[idx]=empty_temp\n",
    "        preds_argmax[idx]=empty_temp.long()\n",
    "    print('Done !')\n",
    "\n",
    "    return preds,preds_tta,preds_argmax,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions that produce the confusion matrix results and is used to get the Mean ratio of intersection scores seen in the report \n",
    "def generate_confusion(pred:Tensor, y_true:Tensor,learn:Learner):\n",
    "        \"Average and Per Image Confusion: intersection of pixels given a true label, true label sums to 1\"\n",
    "       \n",
    "        pred_class= pred\n",
    "        single_img_confusion = []\n",
    "        mean_confusion = []\n",
    "        n =  pred_class.shape[0]\n",
    "        for c_j in range(learn.data.c):\n",
    "            true_binary = y_true.squeeze(1) == c_j# a inary array representing where if each pixel has the class or not for all the iamges n*128*128 array \n",
    "            total_true = true_binary.view(n,-1).sum(dim=1).float()#total number of pixels belonging to a class for each image , its the size of (n)\n",
    "            for c_i in range(learn.data.c):\n",
    "                pred_binary = pred_class == c_i\n",
    "                total_intersect = (true_binary*pred_binary).view(n,-1).sum(dim=1).float()\n",
    "                p_given_t = (total_intersect / (total_true)) #intersection in each image for each class \n",
    "                p_given_t_mean = p_given_t[~torch.isnan(p_given_t)].mean()\n",
    "                single_img_confusion.append(p_given_t)\n",
    "                mean_confusion.append(p_given_t_mean)\n",
    "        single_img_cm = to_np(torch.stack(single_img_confusion).permute(1,0).view(-1, learn.data.c, learn.data.c))\n",
    "        mean_cm = to_np(torch.tensor(mean_confusion).view(learn.data.c, learn.data.c))\n",
    "        return mean_cm, single_img_cm\n",
    "def plot_intersect_cm(self, cm, title=\"Intersection with Predict given True\"):\n",
    "        \"Plot confusion matrices: self.mean_cm or self.single_img_cm generated by `_generate_confusion`\"\n",
    "        from IPython.display import display, HTML\n",
    "        fig,ax=plt.subplots(1,1,figsize=(10,10))\n",
    "        im=ax.imshow(cm, cmap=\"Blues\")\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"True\")\n",
    "        ax.set_title(f\"{title}\")\n",
    "        ax.set_xticks(range(self.data.c))\n",
    "        ax.set_yticks(range(self.data.c))\n",
    "        ax.set_xticklabels(self.data.classes, rotation='vertical')\n",
    "        ax.set_yticklabels(self.data.classes)\n",
    "        fig.colorbar(im)\n",
    "        \n",
    "        df = (pd.DataFrame([self.data.classes, cm.diagonal()], index=['label', 'score'])\n",
    "            .T.sort_values('score', ascending=False))\n",
    "        with pd.option_context('display.max_colwidth', -1):\n",
    "            display(HTML(df.to_html(index=False)))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fil;e names need to be changed for the model file names \n",
    "for i in [1,2,3,4,5]:\n",
    "    if i == 1:\n",
    "        learn.load('/cs/home/khfy6uat/bin/models/baseline_unet_fold_0')\n",
    "    elif i == 2:\n",
    "        learn.load('/cs/home/khfy6uat/bin/models/baseline_unet_fold_1')\n",
    "    elif i == 3:\n",
    "        learn.load('/cs/home/khfy6uat/bin/models/baseline_unet_fold_2')\n",
    "    elif i == 4:\n",
    "        learn.load('/cs/home/khfy6uat/bin/models/baseline_unet_fold_3')\n",
    "    elif i == 5:\n",
    "        learn.load('/cs/home/khfy6uat/bin/models/baseline_unet_fold_4')\n",
    "    \n",
    "    CMS=[]\n",
    "    dices = []\n",
    "    dices_ad=[]\n",
    "    ious=[]\n",
    "    scores, best_thrs = [],[]\n",
    "    cm_score=[]\n",
    "    preds,preds_tta,preds_arg,ys=get_multi_preds(learn,correct=False)\n",
    "    all_preds = [preds,preds_tta,preds_arg]\n",
    "    thrs = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "########################## GETTING RESULTS WITH CONSTANT THRESH\n",
    "    for preds in all_preds:\n",
    "        dices = []\n",
    "        dices_ad=[]\n",
    "        ious=[]\n",
    "        CMS=[]\n",
    "\n",
    "        th=0.3\n",
    "        preds_m=(preds>th).long()\n",
    "        CMS.append(CM_overall(learn,preds_m,ys))\n",
    "        dices.append(dice_overall(preds_m, ys))\n",
    "        dices_ad.append(dice_overall_adjusted(preds_m, ys))\n",
    "        ious.append(iou_overall(preds_m, ys))\n",
    "        print(CMS,dices,dices_ad,ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for one case models\n",
    "for i in [1,2,3,4,5]:\n",
    "    if i == 1:\n",
    "        learn.load('/cs/home/khfy6uat/bin/models/One_class_unet_fold_0')\n",
    "    elif i == 2:\n",
    "        learn.load('/cs/home/khfy6uat/bin/models/One_class_unet_fold_1')\n",
    "    elif i == 3:\n",
    "        learn.load('/cs/home/khfy6uat/bin/models/One_class_unet_fold_2')\n",
    "    elif i == 4:\n",
    "        learn.load('/cs/home/khfy6uat/bin/models/One_class_unet_fold_3')\n",
    "    elif i == 5:\n",
    "        learn.load('/cs/home/khfy6uat/bin/models/One_class_unet_fold_4')\n",
    "    dices = []\n",
    "    dices_ad=[]\n",
    "    ious=[]\n",
    "    scores, best_thrs = [],[]\n",
    "    cm_score=[]\n",
    "    preds,preds_tta,preds_arg,ys=get_multi_preds(learn,correct=True,idx=idx_empty)\n",
    "    all_preds = [preds,preds_tta,preds_arg]\n",
    "    thrs = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "    for preds in all_preds:\n",
    "        dices = []\n",
    "        dices_ad=[]\n",
    "        ious=[]\n",
    "        CMS=[]\n",
    "\n",
    "        th=0.3\n",
    "        preds_m=(preds>th).long()\n",
    "        CMS.append(CM_overall(learn,preds_m,ys))\n",
    "        dices.append(dice_overall(preds_m, ys))\n",
    "        dices_ad.append(dice_overall_adjusted(preds_m, ys))\n",
    "        ious.append(iou_overall(preds_m, ys))\n",
    "        print(CMS,dices,dices_ad,ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for test set\n",
    "# preds, _ = learn.get_preds(ds_type=DatasetType.Test)\n",
    "preds,_=pred_with_flip(learn,ds_type=DatasetType.Test)\n",
    "preds = (preds>.3).long().numpy()\n",
    "print(preds.sum())\n",
    "p,_=learn_cnn.get_preds(ds_type=DatasetType.Test)# getting predications \n",
    "#get predication of CNN and get class with higher confidence\n",
    "pred_cnn=F.softmax(p,1).argmax(dim=1)\n",
    "#find indicices that have negative class (here negative is labeled as (1)) ONLY FOR ONE CASE MODEL\n",
    "idx_empty=pred_cnn==1\n",
    "print(idx_empty.sum(),3250-idx_empty.sum())\n",
    "preds[idx_empty]=empty_temp\n",
    "# Generate rle encodings (images are first converted to the original size)\n",
    "rles = []\n",
    "for p in progress_bar(preds):\n",
    "    im = PIL.Image.fromarray((p.T*255).astype(np.uint8)).resize((1024,1024))\n",
    "    im = np.asarray(im)\n",
    "    rles.append(mask2rle(im, 1024, 1024))\n",
    "ids = [o.stem for o in data.test_ds.items]\n",
    "sub_df = pd.DataFrame({'ImageId': ids, 'EncodedPixels': rles})\n",
    "sub_df.loc[sub_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\n",
    "sub_df.to_csv('Normal_unet_JACC_BN_corrected_f1256.csv', index=False)\n",
    "sub_df.head()\n",
    "!kaggle competitions submit -c siim-acr-pneumothorax-segmentation -f Normal_unet_JACC_BN_corrected_f1256.csv -m \"Unet: JACC loss BN , CNN: f1 score 256 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}