{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Usama zidan\n",
    "Id: 18025713\n",
    "######\n",
    "This file handles loading the data, training and exporting the classifier model\n",
    "Most of functions used are well documented in the fastai liberary site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from fastai import *\n",
    "# import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fastai\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from class_loss import * # classifier loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.fastai import WandbCallback\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import OverSamplingCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising logging framwork\n",
    "run = wandb.init(project='Classifier',name=\"224oversampled\",reinit =True)\n",
    "\n",
    "wandb.config.batch_size = 32\n",
    "wandb.config.img_size = (256, 256)\n",
    "wandb.config.learning_rate =1e-3\n",
    "wandb.config.weight_decay = 1e-2\n",
    "wandb.config.num_epochs = 6+12\n",
    "wandbclc=partial(WandbCallback,log=\"all\",input_type='images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the training set and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=True, flip_vert=False, max_lighting=0.1, max_zoom=1.05,\n",
    "                      max_warp=0.,\n",
    "                      xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n",
    "                                 symmetric_warp(magnitude=(-0.2, 0.2))])\n",
    "\n",
    "\n",
    "path = '/cs/home/khfy6uat/data/classification_1024/classifier_data' #PATH TO DATASET\n",
    "seed = 10\n",
    "data = (ImageList.from_folder(path)\n",
    "        .split_by_rand_pct(seed=10)\n",
    "        .label_from_folder()\n",
    "        .transform(tfms, size=224)\n",
    "        .databunch(bs=13).normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(12,9)) # displays a batch of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data # displays the data details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class names and number of classes\n",
    "print(data.classes)\n",
    "len(data.classes),data.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = partial(fbeta, thresh=0.2, beta = 0.5)\n",
    "per = Precision()\n",
    "rec= Recall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels # model library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "def resnext50_32x4d(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n",
    "    return nn.Sequential(*list(model.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics \n",
    "def fbeta_0(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True)->Rank0Tensor:\n",
    "    \"Computes the f_beta between `preds` and `targets`\"\n",
    "    beta2 = beta ** 2\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred = (y_pred[:,0]>thresh).float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum(dim=-1)\n",
    "    prec = TP/(y_pred.sum(dim=-1)+eps)\n",
    "    rec = TP/(y_true.sum(dim=-1)+eps)\n",
    "    res = (prec*rec)/(prec+rec+eps)*2\n",
    "    return res.mean()\n",
    "def fbeta_1(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True)->Rank0Tensor:\n",
    "    \"Computes the f_beta between `preds` and `targets`\"\n",
    "    beta2 = beta ** 2\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred = (y_pred[:,1]>thresh).float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum(dim=-1)\n",
    "    prec = TP/(y_pred.sum(dim=-1)+eps)\n",
    "    rec = TP/(y_true.sum(dim=-1)+eps)\n",
    "    res = (prec*rec)/(prec+rec+eps)*2\n",
    "    return res.mean()\n",
    "def fbeta_thr(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True)->Rank0Tensor:\n",
    "    \"Computes the f_beta between `preds` and `targets`\"\n",
    "    beta2 = beta ** 2\n",
    "    y_pred.float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum(dim=-1)\n",
    "    prec = TP/(y_pred.sum(dim=-1)+eps)\n",
    "    rec = TP/(y_true.sum(dim=-1)+eps)\n",
    "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
    "    return res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/cs/home/khfy6uat/data/classification_1024/classifier_data'\n",
    "seed = 10\n",
    "data = (ImageList.from_folder(path)\n",
    "        .split_by_rand_pct(0)\n",
    "        .label_from_folder()\n",
    "        .transform(tfms, size=512)\n",
    "        .databunch(bs=6).normalize(imagenet_stats))\n",
    "SEED=2020\n",
    "# train_path = \n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "df=data.to_df()\n",
    "print(df)\n",
    "for train_index,val_index in kf.split(df.index,df['y']):\n",
    "    print(train_index.shape,val_index)\n",
    "    data_fold=(ImageList.from_df(df,path)\n",
    "        .split_by_idxs(train_index,val_index)\n",
    "        .label_from_df()\n",
    "        .transform(tfms, size=224)\n",
    "        .databunch(num_workers=0,bs=64).normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, resnext50_32x4d, pretrained=True, cut=-2,\n",
    "                    split_on=lambda m: (m[0][3], m[1]), \n",
    "                    metrics=[per,rec,fbeta_0,fbeta_1,AUROC()],callback_fns=[wandbclc])\n",
    "learn.callbacks=[OverSamplingCallback(learn)]\n",
    "# learn.loss_fn = fbeta_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data,models.densenet201, metrics=[per,rec,fbeta_0,fbeta_1,AUROC()])\n",
    "learn.loss_fn = fbeta_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cooment in, to load an already trained model, specfy full path below without the 'pth' extension\n",
    "# learn.load('f1model')\n",
    "# learn.data=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.opt_func=RAdam # specifying which optimiser to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNNING LEARNING RATE FINDER TO FIND BEST LEARNING RATE \n",
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 training with size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.loss_func=F1_loss_sig_all() # loading loss function\n",
    "# first training cycle, 24 epochs with lr 0.02 and wieght decay 0.000005\n",
    "learn.fit_one_cycle(24, max_lr=slice(2e-2), wd=1e-5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unfreeezing early layers for training\n",
    "learn.unfreeze();\n",
    "#gradient clipping\n",
    "learn = learn.clip_grad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second training cycle, 32 epochs with cyclic lr 0.0003 and wieght decay 0.00000005\n",
    "lr = [3e-3/100, 3e-3/20, 3e-3/10]\n",
    "learn.fit_one_cycle(32, lr, wd=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Adding cutout augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SZ = 224\n",
    "cutout_frac = 0.20\n",
    "p_cutout = 0.75\n",
    "cutout_sz = round(SZ*cutout_frac)\n",
    "cutout_tfm = cutout(n_holes=(1,1), length=(cutout_sz, cutout_sz), p=p_cutout)\n",
    "\n",
    "tfms = get_transforms(do_flip=True, max_rotate=15, flip_vert=False, max_lighting=0.1,\n",
    "                      max_zoom=1.05, max_warp=0.,\n",
    "                      xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n",
    "                                 symmetric_warp(magnitude=(-0.2, 0.2)), cutout_tfm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = (ImageList.from_folder(path)\n",
    "        .split_by_rand_pct(seed=10)\n",
    "        .label_from_folder()\n",
    "        .transform(tfms, size=224)\n",
    "        .databunch(bs=32).normalize(imagenet_stats))\n",
    "\n",
    "learn.data = data\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd training cycle, 24 epochs with lr 0.02 and wieght decay 0.00006\n",
    "learn.fit_one_cycle(24, slice(2e-2), wd=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unfreezing and gradient clipping\n",
    "learn.unfreeze();\n",
    "learn = learn.clip_grad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final training cycle, 32 epochs with lr 0.0001 and wieght decay 0.000005\n",
    "lr = [1e-3/200, 1e-3/20, 1e-3/10]\n",
    "learn.fit_one_cycle(32, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "learn.save('/cs/home/khfy6uat/bin/classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "tfms = get_transforms(do_flip=True, flip_vert=False, max_lighting=0.1, max_zoom=1.05,\n",
    "                      max_warp=0.,\n",
    "                      xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n",
    "                                 symmetric_warp(magnitude=(-0.2, 0.2))])\n",
    "\n",
    "data = (ImageList.from_folder(path)\n",
    "        .split_by_rand_pct(seed=10)\n",
    "        .label_from_folder()\n",
    "        .transform(tfms, size=512)\n",
    "        .databunch(bs=5).normalize(imagenet_stats))\n",
    "\n",
    "learn.data = data\n",
    "# learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.callback_fns=[wandbclc]\n",
    "learn.loss_func=fbeta_loss_sig_all()\n",
    "learn.fit_one_cycle(12, max_lr=slice(2e-2), wd=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze();\n",
    "learn = learn.clip_grad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = [1e-3/200, 1e-3/20, 1e-3/10]\n",
    "learn.fit_one_cycle(24, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save('/cs/home/khfy6uat/bin/Focal_f1score224256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr(),learn.recorder.plot_metrics(),learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wandb.history.torch\n",
    "# learn.export('cnnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "from fastai.metrics import error_rate\n",
    "from fastai.metrics import Precision\n",
    "from fastai.metrics import Recall\n",
    "per = Precision()\n",
    "rec= Recall()\n",
    "def resnext50_32x4d(pretrained=False):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n",
    "    return nn.Sequential(*list(model.children()))\n",
    "wandbclc=partial(WandbCallback,log=\"all\",input_type='images',monitor='recall',mode='max')\n",
    "learn = cnn_learner(data, resnext50_32x4d, pretrained=True, cut=-2,\n",
    "                split_on=lambda m: (m[0][3], m[1]), \n",
    "                    metrics=[per,rec,error_rate],callback_fns=[wandbclc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fastprogress\n",
    "fastprogress.fastprogress.NO_BAR = True\n",
    "master_bar, progress_bar = fastprogress.fastprogress.force_console_behavior()\n",
    "fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar\n",
    "fastai.basic_data.master_bar, fastai.basic_data.progress_bar = master_bar, progress_bar\n",
    "dataclass.master_bar, dataclass.progress_bar = master_bar, progress_bar\n",
    "\n",
    "fastai.core.master_bar, fastai.core.progress_bar = master_bar, progress_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(data):\n",
    "   \n",
    "    return learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_learner(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torchvision\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from fastai import *\n",
    "def train(learn):\n",
    "    import fastprogress\n",
    "\n",
    "    # import cv2 as cv\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import fastai\n",
    "    from sklearn.model_selection import KFold\n",
    "    from wandb.fastai import WandbCallback\n",
    "    import wandb\n",
    "    from torch import nn\n",
    "    import torch.nn.functional as F\n",
    "    ALPHA = 2.0\n",
    "    BETA = 10000.5\n",
    "    GAMMA = 10\n",
    "    import pretrainedmodels\n",
    "    def resnext50_32x4d(pretrained=False):\n",
    "        pretrained = 'imagenet' if pretrained else None\n",
    "        model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n",
    "        return nn.Sequential(*list(model.children()))\n",
    "    class FocalLoss(nn.Module):\n",
    "        def __init__(self, alpha=1., gamma=2.):\n",
    "            super().__init__()\n",
    "            self.alpha = alpha\n",
    "            self.gamma = gamma\n",
    "\n",
    "        def forward(self, inputs, targets, **kwargs):\n",
    "            CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "            pt = torch.exp(-CE_loss)\n",
    "            F_loss = self.alpha * ((1-pt)**self.gamma) * CE_loss\n",
    "            return F_loss.mean()\n",
    "    print(1)\n",
    "    path = '/cs/home/khfy6uat/data/classification_1024/classifier_data'\n",
    "\n",
    "    fastprogress.fastprogress.NO_BAR = True\n",
    "    master_bar, progress_bar = fastprogress.fastprogress.force_console_behavior()\n",
    "    fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar\n",
    "    fastai.basic_data.master_bar, fastai.basic_data.progress_bar = master_bar, progress_bar\n",
    "    dataclass.master_bar, dataclass.progress_bar = master_bar, progress_bar\n",
    "\n",
    "    fastai.core.master_bar, fastai.core.progress_bar = master_bar, progress_bar\n",
    "#     def resnext50_32x4d(pretrained=False):\n",
    "#         pretrained = 'imagenet' if pretrained else None\n",
    "#         model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n",
    "#         return nn.Sequential(*list(model.children()))\n",
    "#     class FocalLoss(nn.Module):\n",
    "#         def __init__(self, alpha=1., gamma=2.):\n",
    "#             super().__init__()\n",
    "#             self.alpha = alpha\n",
    "#             self.gamma = gamma\n",
    "\n",
    "#         def forward(self, inputs, targets, **kwargs):\n",
    "#             CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "#             pt = torch.exp(-CE_loss)\n",
    "#             F_loss = self.alpha * ((1-pt)**self.gamma) * CE_loss\n",
    "#             return F_loss.mean()\n",
    "    sz=0\n",
    "    sz1=0\n",
    "    # Default values for hyper-parameters we're going to sweep over\n",
    "    config_defaults = {\n",
    "        'epochs': 2,\n",
    "        'batch_size': 12,\n",
    "        'weight_decay': 0.0005,\n",
    "        'learning_rate': 1e-3,\n",
    "        'seed': 42,\n",
    "        'encoder_size':128,\n",
    "        'decoder_size':224\n",
    "    }\n",
    "      # Initialize a new wandb run\n",
    "    wandb.init(config=config_defaults)\n",
    "    \n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "    \n",
    "    sz=(config.encoder_size)\n",
    "\n",
    "    sz1=(config.decoder_size)\n",
    "\n",
    "\n",
    "    tfms = get_transforms(do_flip=True, flip_vert=False, max_lighting=0.1, max_zoom=1.05,\n",
    "                      max_warp=0.,\n",
    "                      xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n",
    "                                 symmetric_warp(magnitude=(-0.2, 0.2))])\n",
    "    print('right before data')\n",
    "    data = (ImageList.from_folder(path)\n",
    "        .split_by_rand_pct(seed=10)\n",
    "        .label_from_folder()\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=12).normalize(imagenet_stats))\n",
    "    print('right before learner')\n",
    "    wandbclc=partial(WandbCallback,log=\"all\",input_type='images',monitor='recall',mode='max')\n",
    "    per = Precision()\n",
    "    rec= Recall()\n",
    "\n",
    "#     learn = cnn_learner(data, resnext50_32x4d, pretrained=True, cut=-2,\n",
    "#                     split_on=lambda m: (m[0][3], m[1]), \n",
    "#                         metrics=[per,rec,error_rate],callback_fns=[wandbclc])   \n",
    "    print(learn.data.train_dl.batch_size)  \n",
    "    lr=config.learning_rate\n",
    "    print(config.epochs)\n",
    "    learn.fit_one_cycle(config.epochs, max_lr=slice(lr), wd=1e-5)\n",
    "    \n",
    "    learn.unfreeze();\n",
    "    learn = learn.clip_grad();\n",
    "    lr = [lr/200, lr/20, lr/10]\n",
    "\n",
    "    learn.fit_one_cycle(config.epochs, max_lr=slice(lr), wd=1e-5)\n",
    "\n",
    "    if (sz1 > 0):\n",
    "        SZ = sz1\n",
    "        cutout_frac = 0.20\n",
    "        p_cutout = 0.75\n",
    "        cutout_sz = round(SZ*cutout_frac)\n",
    "        cutout_tfm = cutout(n_holes=(1,1), length=(cutout_sz, cutout_sz), p=p_cutout)\n",
    "\n",
    "        tfms = get_transforms(do_flip=True, max_rotate=15, flip_vert=False, max_lighting=0.1,\n",
    "                              max_zoom=1.05, max_warp=0.,\n",
    "                              xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n",
    "                                         symmetric_warp(magnitude=(-0.2, 0.2)), cutout_tfm])\n",
    "        data = (ImageList.from_folder(path)\n",
    "            .split_by_rand_pct(seed=10)\n",
    "            .label_from_folder()\n",
    "            .transform(tfms, size=sz1)\n",
    "            .databunch(bs=12).normalize(imagenet_stats))\n",
    "\n",
    "        learn.data=data\n",
    "        learn.fit_one_cycle(config.epochs, max_lr=slice(lr), wd=1e-5)\n",
    "\n",
    "        learn.unfreeze();\n",
    "        learn = learn.clip_grad();\n",
    "        lr = [lr/200, lr/20, lr/10]\n",
    "\n",
    "        learn.fit_one_cycle(config.epochs, max_lr=slice(lr), wd=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the sweep – specify the parameters to search through, the search strategy, the optimization metric et all.\n",
    "sweep_config = {\n",
    "    'controller':{'type':'local'\n",
    "    },\n",
    "    'method': 'grid', #grid, random\n",
    "    'metric': {\n",
    "      'name': 'recall',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'epochs': {\n",
    "            'values': [24, 32, 39,20]\n",
    "        },\n",
    "        'encoder_size': {\n",
    "            'values': [128,224,256]\n",
    "        },\n",
    "        'decoder_size':{\n",
    "            'values':[128,224,256,0]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [1e-2, 1e-3, 1e-4, 3e-4, 3e-5, 1e-5]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity=\"usama_ml\", project=\"testing_sweeps_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sweep = wandb.controller(sweep_id)\n",
    "sweep.run()\n",
    "\n",
    "while not sweep.done():\n",
    "    sweep.print_status()\n",
    "    sweep.step()\n",
    "    train(learn)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sweep sweep_grid_f1loss_trials.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb agent usama_ml/OneClass_segmentation_group_normalization_testing_2/aewda6a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.export('fastai_resnet.pkl');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn = load_learner('/cs/home/khfy6uat/data/classfication_128/classifier_data/','fastai_resnet.pkl', ImageList.from_folder('/cs/home/khfy6uat/data/data1024/test/'))\n",
    "preds,_ = learn.get_preds(ds_type=DatasetType.Test)\n",
    "cls_pred = (F.softmax(preds,1)[:,0]<0.99).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_pred = (F.softmax(preds,1)).argmax(1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths = list(map(str,list(learn.data.test_ds.x.items)))\n",
    "all_test_paths = [p.split('/')[-1][:-4] for p in paths]\n",
    "ids = [o.stem for o in learn.data.test_ds.x.items]\n",
    "\n",
    "df_preds = pd.DataFrame()\n",
    "df_preds['test_paths'] = ids\n",
    "df_preds['class_pred'] = cls_pred\n",
    "\n",
    "df_preds.set_index('test_paths',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_dis_idx = df_preds[df_preds.class_pred==1].index\n",
    "len(no_dis_idx),3205-(len(no_dis_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('/cs/home/khfy6uat/bin/submission_128_244_256_tfms.csv'\n",
    "                  ,index_col='ImageId')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.loc[no_dis_idx] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('sub_classifier_correction_thresh_new_model_unshnaged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -r */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('/cs/home/khfy6uat/bin/sub_classifier_correction.csv'\n",
    "                  ,index_col='ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.data=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds[11:20,0],preds[11:20,1],ys[11:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds,ys = learn.get_preds(ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.9, sigmoid:bool=False):\n",
    "    \"Computes the f_beta between `preds` and `targets`\"\n",
    "  \n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "#     y_pred = (y_pred>thresh).float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum()\n",
    "    prec = TP/(y_pred.sum())\n",
    "    rec = TP/(y_true.sum())\n",
    "    res = ((prec*rec)/(prec+rec))*2\n",
    "    return res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding a thresh to minimise the number of postives detected \n",
    "fs = []\n",
    "scores, best_thrs = [],[]\n",
    "thrs = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "for th in progress_bar(thrs):  \n",
    "    cls_pred = (F.softmax(preds,1)[:,1]>th).cpu().numpy()\n",
    "    paths = list(map(str,list(learn.data.test_ds.x.items)))\n",
    "    all_test_paths = [p.split('/')[-1][:-4] for p in paths]\n",
    "    ids = [o.stem for o in learn.data.test_ds.x.items]\n",
    "\n",
    "    df_preds = pd.DataFrame()\n",
    "    df_preds['test_paths'] = ids\n",
    "    df_preds['class_pred'] = cls_pred\n",
    "\n",
    "    df_preds.set_index('test_paths',inplace=True)\n",
    "    no_dis_idx = df_preds[df_preds.class_pred==1].index\n",
    "    fs.append(3205-(len(no_dis_idx)))\n",
    "fs=np.array(fs)\n",
    "scores.append(fs.min())\n",
    "best_thrs.append(thrs[fs.argmin()])\n",
    "best_thr = np.array(best_thrs).mean()\n",
    "\n",
    "best_dice = fs.min()\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(thrs, fs)\n",
    "plt.vlines(x=best_thrs[-1], ymin=fs.min(), ymax=fs.max())\n",
    "plt.text(best_thrs[-1]+0.03, best_dice-0.01, f'F1 = {best_dice:.3f}', fontsize=14);\n",
    "plt.show(),best_dice,best_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys=ys\n",
    "preds_=preds[:,1]\n",
    "n = ys.shape[0]\n",
    "preds_sig=preds_\n",
    "# preds_sig=preds_.sigmoid()\n",
    "# preds_sig=F.softmax(preds_,1)\n",
    "thrs = np.arange(0.01, 1, 0.01)\n",
    "targs = ys\n",
    "fs = []\n",
    "scores, best_thrs = [],[]\n",
    "for th in progress_bar(thrs):\n",
    "    pred = (preds_sig>th)\n",
    "    fs.append(fbeta_thr(pred,targs))\n",
    "fs=np.array(fs)\n",
    "scores.append(fs.max())\n",
    "best_thrs.append(thrs[fs.argmax()])\n",
    "best_thr = np.array(best_thrs).mean()\n",
    "\n",
    "best_dice = fs.max()\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(thrs, fs)\n",
    "plt.vlines(x=best_thrs[-1], ymin=fs.min(), ymax=fs.max())\n",
    "plt.text(best_thrs[-1]+0.03, best_dice-0.01, f'F1 = {best_dice:.3f}', fontsize=14);\n",
    "plt.show()\n",
    "    \n",
    "# pre = preds.argmax(-1).view(-1).cpu()\n",
    "# tar = ys.cpu()\n",
    "\n",
    "# fbeta(pred,targs),preds_sig,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbeta_0(preds,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds[:,0]),(preds[:,0]).sigmoid(),preds[:,1],preds[:,1].sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.softmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w= [2,1,2]\n",
    "for i,v in w.items():\n",
    "    print(i,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import fastai\n",
    "from fastai.callbacks import TrackerCallback\n",
    "from pathlib import Path\n",
    "import random\n",
    "try:\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')  # non-interactive backend (avoid tkinter issues)\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    print('Warning: matplotlib required if logging sample image predictions')\n",
    "\n",
    "class WandbCallback(TrackerCallback):\n",
    "    \"\"\"\n",
    "    Automatically saves model topology, losses & metrics.\n",
    "    Optionally logs weights, gradients, sample predictions and best trained model.\n",
    "    Args:\n",
    "        learn (fastai.basic_train.Learner): the fast.ai learner to hook.\n",
    "        log (str): \"gradients\", \"parameters\", \"all\", or None. Losses & metrics are always logged.\n",
    "        save_model (bool): save model at the end of each epoch. It will also load best model at the end of training.\n",
    "        monitor (str): metric to monitor for saving best model. None uses default TrackerCallback monitor value.\n",
    "        mode (str): \"auto\", \"min\" or \"max\" to compare \"monitor\" values and define best model.\n",
    "        input_type (str): \"images\" or None. Used to display sample predictions.\n",
    "        validation_data (list): data used for sample predictions if input_type is set.\n",
    "        predictions (int): number of predictions to make if input_type is set and validation_data is None.\n",
    "        seed (int): initialize random generator for sample predictions if input_type is set and validation_data is None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Record if watch has been called previously (even in another instance)\n",
    "    _watch_called = False\n",
    "\n",
    "    def __init__(self,\n",
    "                 learn,\n",
    "                 log=\"gradients\",\n",
    "                 save_model=True,\n",
    "                 monitor=None,\n",
    "                 mode='auto',\n",
    "                 input_type=None,\n",
    "                 validation_data=None,\n",
    "                 predictions=36,\n",
    "                 seed=12345):\n",
    "\n",
    "        # Check if wandb.init has been called\n",
    "        if wandb.run is None:\n",
    "            raise ValueError(\n",
    "                'You must call wandb.init() before WandbCallback()')\n",
    "\n",
    "        # Adapted from fast.ai \"SaveModelCallback\"\n",
    "        if monitor is None:\n",
    "            # use default TrackerCallback monitor value\n",
    "            super().__init__(learn, mode=mode)\n",
    "        else:\n",
    "            super().__init__(learn, monitor=monitor, mode=mode)\n",
    "        self.save_model = save_model\n",
    "        self.model_path = Path(wandb.run.dir) / 'bestmodel.pth'\n",
    "\n",
    "        self.log = log\n",
    "        self.input_type = input_type\n",
    "        self.best = None\n",
    "\n",
    "        # Select items for sample predictions to see evolution along training\n",
    "        self.validation_data = validation_data\n",
    "        if input_type and not self.validation_data:\n",
    "            wandbRandom = random.Random(seed)  # For repeatability\n",
    "            predictions = min(predictions, len(learn.data.valid_ds))\n",
    "            indices = wandbRandom.sample(range(len(learn.data.valid_ds)),\n",
    "                                         predictions)\n",
    "            self.validation_data = [learn.data.valid_ds[i] for i in indices]\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        \"Call watch method to log model topology, gradients & weights\"\n",
    "\n",
    "        # Set self.best, method inherited from \"TrackerCallback\" by \"SaveModelCallback\"\n",
    "        super().on_train_begin()\n",
    "\n",
    "        # Ensure we don't call \"watch\" multiple times\n",
    "        if not WandbCallback._watch_called:\n",
    "            WandbCallback._watch_called = True\n",
    "\n",
    "            # Logs model topology and optionally gradients and weights\n",
    "            wandb.watch(self.learn.model, log=self.log)\n",
    "\n",
    "    def on_epoch_end(self, epoch, smooth_loss, last_metrics, **kwargs):\n",
    "        \"Logs training loss, validation loss and custom metrics & log prediction samples & save model\"\n",
    "\n",
    "        if self.save_model:\n",
    "            # Adapted from fast.ai \"SaveModelCallback\"\n",
    "            current = self.get_monitor_value()\n",
    "            if current is not None and self.operator(current, self.best):\n",
    "                print(\n",
    "                    'Better model found at epoch {} with {} value: {}.'.format(\n",
    "                        epoch, self.monitor, current))\n",
    "                self.best = current\n",
    "\n",
    "                # Save within wandb folder\n",
    "                with self.model_path.open('wb') as model_file:\n",
    "                    self.learn.save(model_file)\n",
    "\n",
    "        # Log sample predictions if learn.predict is available\n",
    "        if self.validation_data:\n",
    "            try:\n",
    "                self._wandb_log_predictions()\n",
    "#                 self._log_otherstuff()\n",
    "            except FastaiError as e:\n",
    "                wandb.termwarn(e.message)\n",
    "                self.validation_data = None  # prevent from trying again on next loop\n",
    "            except Exception as e:\n",
    "                wandb.termwarn(\"Unable to log prediction samples.\\n{}\".format(e))\n",
    "                self.validation_data=None  # prevent from trying again on next loop\n",
    "\n",
    "        # Log losses & metrics\n",
    "        # Adapted from fast.ai \"CSVLogger\"\n",
    "        logs = {\n",
    "            name: stat\n",
    "            for name, stat in list(\n",
    "                zip(self.learn.recorder.names, [epoch, smooth_loss] +\n",
    "                    last_metrics))\n",
    "        }\n",
    "        wandb.log(logs)\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "    def on_train_end(self, **kwargs):\n",
    "        \"Load the best model.\"\n",
    "\n",
    "        if self.save_model:\n",
    "            # Adapted from fast.ai \"SaveModelCallback\"\n",
    "            if self.model_path.is_file():\n",
    "                with self.model_path.open('rb') as model_file:\n",
    "                    self.learn.load(model_file, purge=False)\n",
    "                    print('Loaded best saved model from {}'.format(\n",
    "                        self.model_path))\n",
    "\n",
    "    def _log_otherstuff(self):\n",
    "        preds,y,losses = self.learn.get_preds(with_loss=True)\n",
    "\n",
    "        interp = ClassificationInterpretation(self.learn, preds, y, losses)\n",
    "\n",
    "        plt_cm=interp.plot_confusion_matrix(return_fig=True)\n",
    "        wandb.log({'roc': wandb.plots.ROC(y, preds, self.learn.data.classes)})\n",
    "        wandb.log({'pr': wandb.plots.precision_recall(y, preds, self.learn.data.classes)})\n",
    "        wandb.log({\"CM\": plt_cm})\n",
    "        \n",
    "    def _wandb_log_predictions(self):\n",
    "        \"Log prediction samples\"\n",
    "\n",
    "        pred_log = []\n",
    "        pred_log_2=[]\n",
    "        y_log=[]\n",
    "        for x, y in self.validation_data:\n",
    "            \n",
    "            try:\n",
    "                pred=self.learn.predict(x)\n",
    "                pred_log_2.append(pred[2])\n",
    "                y_log.append(y)\n",
    "            except:\n",
    "                raise FastaiError('Unable to run \"predict\" method from Learner to log prediction samples.')\n",
    "\n",
    "            # scalar -> likely to be a category\n",
    "            # tensor of dim 1 -> likely to be multicategory\n",
    "            if not pred[1].shape or pred[1].dim() == 1:\n",
    "                pred_log.append(\n",
    "                    wandb.Image(\n",
    "                        x.data,\n",
    "                        caption='Ground Truth: {}\\nPrediction: {}'.format(\n",
    "                            y, pred[0])))\n",
    "\n",
    "            # most vision datasets have a \"show\" function we can use\n",
    "            elif hasattr(x, \"show\"):\n",
    "                # log input data\n",
    "                pred_log.append(\n",
    "                    wandb.Image(x.data, caption='Input data', grouping=3))\n",
    "\n",
    "                # log label and prediction\n",
    "                for im, capt in ((pred[0], \"Prediction\"),\n",
    "                                 (y, \"Ground Truth\")):\n",
    "                    # Resize plot to image resolution\n",
    "                    # from https://stackoverflow.com/a/13714915\n",
    "                    my_dpi = 100\n",
    "                    fig = plt.figure(frameon=False, dpi=my_dpi)\n",
    "                    h, w = x.size\n",
    "                    fig.set_size_inches(w / my_dpi, h / my_dpi)\n",
    "                    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "                    ax.set_axis_off()\n",
    "                    fig.add_axes(ax)\n",
    "\n",
    "                    # Superpose label or prediction to input image\n",
    "                    x.show(ax=ax, y=im)\n",
    "                    pred_log.append(wandb.Image(fig, caption=capt))\n",
    "                    plt.close(fig)\n",
    "\n",
    "            # likely to be an image\n",
    "            elif hasattr(y, \"shape\") and (\n",
    "                (len(y.shape) == 2) or\n",
    "                    (len(y.shape) == 3 and y.shape[0] in [1, 3, 4])):\n",
    "\n",
    "                pred_log.extend([\n",
    "                    wandb.Image(x.data, caption='Input data', grouping=3),\n",
    "                    wandb.Image(pred[0].data, caption='Prediction'),\n",
    "                    wandb.Image(y.data, caption='Ground Truth')\n",
    "                ])\n",
    "\n",
    "            # we just log input data\n",
    "            else:\n",
    "                pred_log.append(wandb.Image(x.data, caption='Input data'))\n",
    "\n",
    "            wandb.log({\"Prediction Samples\": pred_log}, commit=False)\n",
    "            \n",
    "#             interp = ClassificationInterpretation(self.learn, pred_log_2, y_log, losses)\n",
    "\n",
    "#             plt_cm=interp.plot_confusion_matrix(return_fig=True)\n",
    "        print(torch.stack(y_log),torch.stack(pred_log_2))\n",
    "#         wandb.log({'roc': wandb.plots.ROC(torch.stack(y_log).numpy(), torch.stack(pred_log_2).numpy(), self.learn.data.classes)},commit=False)\n",
    "#         wandb.log({'pr': wandb.plots.precision_recall( torch.stack(y_log).numpy(), torch.stack(pred_log_2).numpy(), self.learn.data.classes)},commit=False)\n",
    "# #             wandb.log({\"CM\": plt_cm})\n",
    "        print(\"LOGGED #####\")\n",
    "\n",
    "class FastaiError(wandb.Error):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=learn.predict(learn.data.valid_dl.x[1])\n",
    "p[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[tensor([0.8460, 0.1540]), tensor([0.6084, 0.3916]), tensor([0.5220, 0.4780]), tensor([0.0553, 0.9447]), tensor([0.9988, 0.0012]), tensor([0.9975, 0.0025]), tensor([0.7724, 0.2276]), tensor([0.9929, 0.0071]), tensor([0.6132, 0.3868]), tensor([0.9828, 0.0172]), tensor([0.0512, 0.9488]), tensor([0.7204, 0.2796]), tensor([0.8214, 0.1786]), tensor([0.9087, 0.0913]), tensor([0.1048, 0.8952]), tensor([0.6428, 0.3572]), tensor([0.7324, 0.2676]), tensor([9.9942e-01, 5.7936e-04]), tensor([0.0310, 0.9690]), tensor([0.9373, 0.0627]), tensor([0.1187, 0.8813]), tensor([0.3811, 0.6189]), tensor([0.8052, 0.1948]), tensor([0.6279, 0.3721]), tensor([0.4554, 0.5446]), tensor([0.7444, 0.2556]), tensor([0.9768, 0.0232]), tensor([0.1312, 0.8688]), tensor([0.7607, 0.2393]), tensor([0.4091, 0.5909]), tensor([0.7046, 0.2954]), tensor([0.6373, 0.3627]), tensor([0.4189, 0.5811]), tensor([0.8620, 0.1380]), tensor([0.1797, 0.8203]), tensor([0.9822, 0.0178])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.stack(l)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(36,2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        \n",
    "        self.degenerated_to_sgd = degenerated_to_sgd\n",
    "        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n",
    "            for param in params:\n",
    "                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n",
    "                    param['buffer'] = [[None, None, None] for _ in range(10)]\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, buffer=[[None, None, None] for _ in range(10)])\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = group['buffer'][int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    elif self.degenerated_to_sgd:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = -1\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                    p.data.copy_(p_data_fp32)\n",
    "                elif step_size > 0:\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "                    p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "class PlainRAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "                    \n",
    "        self.degenerated_to_sgd = degenerated_to_sgd\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "\n",
    "        super(PlainRAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(PlainRAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                beta2_t = beta2 ** state['step']\n",
    "                N_sma_max = 2 / (1 - beta2) - 1\n",
    "                N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                    step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                    p.data.copy_(p_data_fp32)\n",
    "                elif self.degenerated_to_sgd:\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "                    step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "                    p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class AdamW(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, warmup = 0):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        \n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, warmup = warmup)\n",
    "        super(AdamW, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(AdamW, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                \n",
    "                if group['warmup'] > state['step']:\n",
    "                    scheduled_lr = 1e-8 + state['step'] * group['lr'] / group['warmup']\n",
    "                else:\n",
    "                    scheduled_lr = group['lr']\n",
    "\n",
    "                step_size = scheduled_lr * math.sqrt(bias_correction2) / bias_correction1\n",
    "                \n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * scheduled_lr, p_data_fp32)\n",
    "\n",
    "                p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}